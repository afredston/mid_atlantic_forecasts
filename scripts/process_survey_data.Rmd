---
title: "survey data import and harmonization for mid-Atlantic process models"
author: "Alexa Fredston-Hermann"
date: "5/7/2020"
output: html_document
---

This script is based on previous code M. Pinsky wrote to pre-process data for the Atlantic cod forecast challenge, and on compile.R in the OceanAdapt data files. We first crop the trawl data down to the regions and species of interest, and then revisit the raw data files to extract length frequency data. 

Users should specify:

1. The file path to a directory containing a download of OceanAdapt, `OApath`
1. A list of Latin names (format Genus species) of species of interest
1. A list of regions of interest, from: "Aleutian Islands", "Eastern Bering Sea", "Gulf of Alaska", 
"Northeast US Spring", "Northeast US Fall", "West Coast Triennial", 
"West Coast Annual", "Gulf of Mexico", "Southeast US Spring", 
"Southeast US Summer", "Southeast US Fall", "Scotian Shelf"

```{r packages and functions, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE}
library(PBSmapping)
library(tidyverse)
library(here)
library(stringr)
library(lubridate)
library(data.table)
here <- here::here

OApath <- "~/github/OceanAdapt_9815545/"
sppOfInt <- c("Squalus acanthias")
regOfInt <- c("Northeast US Spring", "Northeast US Fall", "Southeast US Spring", "Southeast US Summer", "Southeast US Fall", "Scotian Shelf")
# options: c("Aleutian Islands", "Eastern Bering Sea", "Gulf of Alaska", "Northeast US Spring", "Northeast US Fall", "West Coast Triennial", "West Coast Annual", "Gulf of Mexico", "Southeast US Spring", "Southeast US Summer", "Southeast US Fall", "Scotian Shelf")

```

# Get zero-inflated data from OceanAdapt
```{r dat_exploded, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE}
load(paste0(OApath,"data_clean/dat_exploded.RData"))

dat_exploded_filter <- dat.exploded %>%
  filter(spp %in% sppOfInt,
         region %in% regOfInt
  )
```

# Get length-frequency data from individual surveys

## Northeast US

```{r neus len, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE}
load(paste0(OApath,"data_raw/neus_Survdat.RData"))
load(paste0(OApath, "data_raw/neus_SVSPP.RData"))

neus_len <- survdat %>% 
  # create a haulid for joining with dat.exploded
  mutate(haulid = paste(formatC(CRUISE6, width=6, flag=0), formatC(STATION, width=3, flag=0), formatC(STRATUM, width=4, flag=0), sep='-')) %>% 
  select(haulid, SVSPP, LENGTH, NUMLEN) %>% 
  filter(haulid %in% dat_exploded_filter$haulid) %>% # pare down to hauls of interest 
  left_join(spp, by="SVSPP") %>% # get species names from species codes
  mutate(spp = str_to_sentence(SCINAME)) %>% # change to format of sppOfInt
  filter(spp %in% sppOfInt) %>%
  select(spp, haulid, LENGTH, NUMLEN) %>%
  filter(!is.na(LENGTH))
```

## Scotian Shelf

Doesn't look like this has any length data--just total number and total weight. 

```{r scot len, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE}
scotfiles <- as.list(dir(pattern = "scot", path = "~/github/OceanAdapt_9815545/data_raw", full.names = T))

scotraw <- scotfiles %>% 
  map_dfr(~ read_csv(.x, col_types = cols(
    .default = col_double(),
    MISSION = col_character(),
    SEASON = col_character(),
    SURVEYDATE = col_character(),
    GEAR = col_character(),
    SCIENTIFICNAME = col_character(),
    TAXONOMICNAMEAUTHOR = col_character()
  ))) 
```

## Southeast US

This survey has a lot of weight-related measurements and I'm not totally sure how they relate to each other: SPECIESTOTALWEIGHT, SPECIESSUBWEIGHT, SPECIESWGTPROCESSED, CATCHSUBSAMPLED, CATCHWEIGHT, CATCHSUBWEIGHT. 

```{r seus oa, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE}

seus_catch <- read_csv(unz("~/github/OceanAdapt_9815545/data_raw/seus_catch.csv.zip", "seus_catch.csv"), col_types = cols(.default = col_character())) %>% 
  # remove symbols
  mutate_all(list(~str_replace(., "=", ""))) %>% 
  mutate_all(list(~str_replace(., '"', ''))) %>% 
  mutate_all(list(~str_replace(., '"', ''))) %>%
  mutate(spp = str_to_sentence(SPECIESSCIENTIFICNAME)) %>%
  filter(spp %in% sppOfInt)
```

As per Zoe Kitchel and Ria Kobernuss, the [SEAMAP online data portal](https://www2.dnr.sc.gov/seamap/Account/LogOn?ReturnUrl=%2fseamap%2fReports) does have an option to download finer-scale data that includes length data. They shared it with me (May 14 2020) with the following note, and it's imported below:

*This gives you a CSV. I converted it to an RData file last September, which goes up until 11/16/2018. I just checked, and it hasn't been updated since then, so the RData file we've been using is still up to date.*

```{r seus manual, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE }
load(here("survey-data","seus_trawl_data.Rdata"))

seus_len <- seus_specimens %>%
  rename_all(tolower) %>% 
  mutate_all(tolower) %>% # so dataframe isn't screaming at me
  mutate_all(funs(str_replace(., "=", ""))) %>% # raw data has random equals signs everywhere
  mutate_all(funs(str_replace(., '"', ''))) %>% # also get rid of quotation marks
  mutate_all(funs(str_replace(., '"', ''))) %>% # have to run twice to get rid of leading and trailing quotes, for some reason 
  # mutate_all(na_if, "not applicable") %>% 
  select_if(~!all(is.na(.))) # remove columns that are all NAs

```

I'm not sure how to use the Southeast data because (unlike Northeast) length measurements don't appear to have been recorded on *every* haul, so we won't always have associated length data for positive catches. 

# Summarize length data into length classes

Note that the chunk below is written for one species only (spiny dogfish)--will need to be updated in the future when more species are added in. 

```{r classes,  eval=TRUE, echo=FALSE, results=FALSE, message=FALSE}
dogfish_neus_len <- neus_len %>% filter(spp=="Squalus acanthias") # eventually neus_len will contain other species

dogfish_lm_F <- 75 #cm; see SAW 43 p17
dogfish_lm_M <- 60 

dogfish_lm <- mean(c(dogfish_lm_M, dogfish_lm_F))
dogfish_ljuv <- min(dogfish_neus_len$LENGTH) + (dogfish_lm - min(dogfish_neus_len$LENGTH))/2 # halfway between min size caught and Lm

dogfish_neus_len_agg <- dogfish_neus_len %>%
  mutate(lengthclass = ifelse(LENGTH <= dogfish_ljuv, "smalljuv",
                              ifelse(LENGTH < dogfish_lm, "largejuv", "adult"))) %>% # group lengths into length classes 
  group_by(haulid, spp, lengthclass) %>% 
  summarise(numlengthclass = sum(NUMLEN)) # aggregate counts

dogfish_len_zeros <- expand_grid(haulid=unique(dat_exploded_filter$haulid),  lengthclass=unique(dogfish_neus_len_agg$lengthclass),
                                 spp="Squalus acanthias") %>% # get all possible combinations of haulid and length class 
  left_join(dogfish_neus_len_agg, by=c("spp","haulid","lengthclass")) %>% # add length counts 
  left_join(dat_exploded_filter, by=c("spp","haulid")) %>% # add haul data 
  mutate(numlengthclass = replace_na(numlengthclass, 0)) # replace NAs with true zeroes
```

# Write out data

In a format that can be imported into Python

```{r export df, eval=TRUE, echo=FALSE, results=FALSE, message=FALSE }
# this csv is too big for github, so zip it
write_csv(dogfish_len_zeros, here::here("processed-data", "dogfish_prepped_data.csv"))

zip(zipfile = here::here("processed-data", "dogfish_prepped_data.zip"),
    files = here::here("processed-data", "dogfish_prepped_data.csv"))

file.remove(here::here("processed-data", "dogfish_prepped_data.csv"))

```

