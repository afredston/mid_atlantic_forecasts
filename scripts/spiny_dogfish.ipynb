{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions for model \n",
    "%run model_functions.ipynb\n",
    "%run jude_plot_code.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import random as random\n",
    "import math as math\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from random import triangular\n",
    "import scipy.stats as sst\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import jude_plot_code as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejection\n",
      "in_situ\n"
     ]
    }
   ],
   "source": [
    "# set code preferences for spiny dogfish model\n",
    "year_split = 2008 # in what year should the data be split into estimation (below year_split) or validation (equals to or after year_split)? currently leaving 10 years for forecasting/validation\n",
    "abc_options = ['regression','rejection']\n",
    "abc_pref = abc_options[1] # choose which approach to Approximate Bayesian Computation to use \n",
    "temperature_options = ['ROMS','in_situ'] # ROMS is still the incorrect run from the cod forecast challenge\n",
    "temperature_pref = temperature_options[1]\n",
    "print(abc_pref) # check it's correct, and remember Python starts from 0! \n",
    "print(temperature_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haulid',\n",
       " 'lengthclass',\n",
       " 'spp',\n",
       " 'numlengthclass',\n",
       " 'region',\n",
       " 'year',\n",
       " 'common',\n",
       " 'stratum',\n",
       " 'stratumarea',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'depth',\n",
       " 'btemp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import spiny dogfish data & look at columns \n",
    "dat_trawl = pd.read_csv(\"../processed-data/dogfish_prepped_data.csv\")\n",
    "list(dat_trawl.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haulid', 'numlengthclass', 'year', 'lat', 'lengthclass', 'temp_bottom']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only needed columns and import temperature data if needed \n",
    "if temperature_pref=='ROMS':\n",
    "    dat_trawl = dat_trawl[['haulid','numlengthclass', 'year', 'lat','lengthclass']] # keep only needed columns \n",
    "    dat_roms = pd.read_csv(\"~/github/SDM-convergence/data/haul_ROMS.csv\", usecols = ['unique_id',  'temp_bottom', 'temp_surface']) # import ROMS data \n",
    "    dat_roms.rename({\"unique_id\":\"haulid\"},axis=\"columns\",inplace=True) # fix column names \n",
    "    dat_trawl = pd.merge(dat_estimation, dat_roms, how=\"inner\", on=\"haulid\") # merge with trawl data. because this is an inner join, it will omit NOAA hauls with no ROMS data, and ROMS data with no matches in the species' survey dataframe\n",
    "if temperature_pref=='in_situ':\n",
    "    dat_trawl = dat_trawl[['haulid','numlengthclass', 'year', 'lat','lengthclass','btemp']]\n",
    "    dat_trawl.rename({'btemp':'temp_bottom'},axis=\"columns\",inplace=True)\n",
    "list(dat_trawl.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963\n",
      "2018\n",
      "1963\n",
      "2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afh/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# filter trawl data \n",
    "dat_estimation = dat_trawl.loc[(dat_trawl['year'] < year_split)] # use years before year_split for estimation\n",
    "\n",
    "# check year filtering worked correctly\n",
    "print(dat_trawl.year.min())\n",
    "print(dat_trawl.year.max())\n",
    "\n",
    "print(dat_estimation.year.min())\n",
    "print(dat_estimation.year.max())\n",
    "\n",
    "# round latitudes to integers\n",
    "dat_estimation.lat = dat_estimation.lat.round().astype(np.int) # revisit and be more precise about rounding; currently rounding to nearest integer, so bands are defined as center points (35-degree band runs from 34.51 to 35.49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking care of missing data in both data frames\n",
    "# AF: commenting this out because interpolation is a bit dodgy here. will just deal with NAs \n",
    "# dat_estimation=dat_estimation.interpolate(method ='linear', limit_direction ='forward')\n",
    "# dat_estimation=dat_estimation.interpolate(method ='linear', limit_direction ='backward')\n",
    "# dat_roms =dat_roms.interpolate(method ='linear', limit_direction ='forward')\n",
    "# dat_roms=dat_roms.interpolate(method ='linear', limit_direction ='backward')\n",
    "\n",
    "\n",
    "# USE DF = DF.DROPNA() INSTEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46]\n"
     ]
    }
   ],
   "source": [
    "# track number of latitudes--currently the spatial unit of analysis\n",
    "Nlat = dat_estimation['lat'].max()-dat_estimation['lat'].min()\n",
    "latrange = np.arange(start=dat_estimation.lat.min(), stop=dat_estimation.lat.max(), step=1)\n",
    "print(Nlat)\n",
    "print(latrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afh/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/afh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: Mean of empty slice.\n",
      "/Users/afh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: Mean of empty slice.\n",
      "/Users/afh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:58: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "# here I'm temporarily reversing the changes to object names that I made \n",
    "df=dat_estimation\n",
    "df.rename({\"numlengthclass\":\"NUMLEN\"},axis=\"columns\",inplace=True)\n",
    "#to track the total number of latitudes available\n",
    "nn=df['lat'].max()-df['lat'].min()#15 #AF: add column that preserves true lat value, not just lat index \n",
    "#Libraries to keep track of the patches and stages # AF: make names more intuitive, consider using dataframes instead of dictionaries \n",
    "D={}\n",
    "D1={}\n",
    "# AF: what happens when all values are NA for mean() and sum() below? check that this isn't an issue\n",
    "\n",
    "#extracting the data from the data frames  and storing according to the patch and stage. We start from the first to the last last patch (1:nn+1)  and when in each patch, we extract the number of species for  each life stage, the temperature for each patch (and compute the avaerage for the year)\n",
    "for q in range(1,nn+2): # nn+2 because range() does not use the final value, i.e., range(1,3) equals [1,2]\n",
    "    #Juveniles for patch 33+q( since the min patch is 34, we will start with patch 34 --to the maximum # AF: get rid of all fixed numerics here \n",
    "    D['J_patch'+ str(q)]=df.loc[(df['lat'] == (df['lat'].min()-1)+ q) & (df['lengthclass']=='smalljuv')]\n",
    "    #total number of observations in each patch for each year\n",
    "    n=len(D['J_patch'+ str(q)].year.values)\n",
    "    # the total number of years of data available\n",
    "    m=df['year'].max()-df['year'].min()\n",
    "    #temperature readings when each species was caught in the patch\n",
    "    Abun_TemJ=np.empty((m+1, 3))\n",
    "    kJ=0\n",
    "    kY=0\n",
    "    kA=0\n",
    "    for i in range (0, m+1):\n",
    "        Abun_TemJ[i,0]=kJ\n",
    "        DD=D['J_patch'+ str(q)]\n",
    "        TT=DD.loc[(DD['year'] == 1980+i)]\n",
    "        temp1=DD.loc[(DD['year'] == 1980+i)]\n",
    "     #   print(temp1.temp_bottom.values) # AF: not sure why this is here \n",
    "        Abun_TemJ[i,1]=temp1.temp_bottom.values.mean()\n",
    "        Abun_TemJ[i,2]=TT.NUMLEN.values.sum()\n",
    "        \n",
    "        kJ=kJ +1\n",
    "    #After extracting teh temperature and calculating the mean value, we now save it\n",
    "    D1['J_patch'+ str(q)]=Abun_TemJ\n",
    "# now moving to Young Juveniles to perform teh same process as above\n",
    "    D['Y_patch'+ str(q)]=df[(df['lat'] == 33+ q) & (df['lengthclass']=='largejuv')]\n",
    "    n=len(D['Y_patch'+ str(q)].year.values)\n",
    "    m=df['year'].max()-df['year'].min()\n",
    "    Abun_TemY=np.empty((m+1, 3))\n",
    "    for i in range (0, m+1):\n",
    "        Abun_TemY[i,0]=kY\n",
    "        DD=D['Y_patch'+ str(q)]\n",
    "        TT=DD.loc[(DD['year'] == 1980+i)]\n",
    "        temp1=DD.loc[(DD['year'] == 1980+i)]\n",
    "        Abun_TemY[i,1]=temp1.temp_bottom.values.mean()\n",
    "        Abun_TemY[i,2]=TT.NUMLEN.values.sum()\n",
    "        kY=kY +1\n",
    "    D1['Y_patch'+ str(q)]=Abun_TemY\n",
    "#Next we move to Adult and perform teh same as above\n",
    "    D['A_patch'+ str(q)]=df[(df['lat'] == 33+ q) & (df['lengthclass']=='adult')]\n",
    "    Abun_TemA=np.empty((m+1, 3))\n",
    "    for i in range (0, m+1):\n",
    "        Abun_TemA[i,0]=kA\n",
    "        DD=D['A_patch'+ str(q)]\n",
    "        TT=DD.loc[(DD['year'] == 1980+i)]\n",
    "        temp1=DD.loc[(DD['year'] == 1980+i)]\n",
    "        Abun_TemA[i,1]=temp1.temp_bottom.values.mean()\n",
    "        Abun_TemA[i,2]=TT.NUMLEN.values.sum()\n",
    "        kA=kA +1\n",
    "    D1['A_patch'+ str(q)]=Abun_TemA\n",
    "    \n",
    "    # use pd.ExcelWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that data has been structured in a dictionary for the model, run the model\n",
    "# we already imported the model functions at the top\n",
    "#main script starts from here\n",
    "# if __name__ == '__main__': # AF: ask Jude what this does -- apparently it denotes the main script--commenting out for now \n",
    "# Import the abundance data and data for the other variables e.g temperature\n",
    "#  import groundfish_training AF: this isn't necessary anymore and I deleted \"groundfish_training.\" from all the calls to D1 or D\n",
    "# the total number of generations\n",
    "T_FINAL = len(D1['J_patch1'][:,0])\n",
    "#We simulate 20000 sets of parameters for for ABC, using non informatives priors (uniform priors\n",
    "NUMBER_SIMS = 20000\n",
    "#no of patches\n",
    "no_patches=nn\n",
    "rows=T_FINAL\n",
    "cols=no_patches\n",
    "# creating an array to store the number of juveniles, young juvenils and adults in each patch\n",
    "N_J=np.ndarray(shape=(rows, cols), dtype=float, order='F') # rows are years and columns are patches \n",
    "N_Y=np.ndarray(shape=(rows, cols), dtype=float, order='F')\n",
    "N_A=np.ndarray(shape=(rows, cols), dtype=float, order='F')\n",
    "tempA = np.ndarray(shape=(rows, cols), dtype=float, order='F')\n",
    "#storing data (secies abundance and temeprature time series data ) in the created arrays\n",
    "for q in range(1,no_patches+1):\n",
    "    i=q-1\n",
    "    p=q\n",
    "    N_J[:,i]=D1['J_patch'+ str(p)][:,2] # fill in the array with data from D1. column 2 in D1 holds abundance. column 0 contains indices (kJ, etc) and column 1 contains temperatures. \n",
    "    N_Y[:,i]=D1['Y_patch'+ str(p)][:,2]\n",
    "    N_A[:,i]=D1['A_patch'+ str(p)][:,2]\n",
    "    tempA[:,i]=D1['A_patch'+ str(p)][:,1] # only varies across patches, not life stages, so just need to save 1x \n",
    "#running ABC. See the function for details. returns all the observe summary statitics (OS)and simulated summary statistics (SS) in a matrix with first row corresponding to OS and the rest of the rows to SS as well as the parameter values that led to the simulated summary statistics.\n",
    "param_save, Obs_Sim         = run_sim()\n",
    "\n",
    "#normalize the rows of Obs_sim to have NOS in row 1 and NSS in the remaining rows. Substract rows i=2:NUMBER_SIMS from row 1 of Obs_sim (whic contain OS).Compute the eucleadean distance (d) between NSS and NOS then use it along side tolerance (δ), to determine all parameters and NSS corresponding to d ≤ δ.Choose δ such that δ × 100% of the NUMBER_SIMS simulated parameters and NSS are selected. retain the parameters that made this threshold (library), the weights ot be used in local linear regression and the NSS that meets the threshold (stats)\n",
    "library, dists, stats,stats_SS,  NSS_cutoff, library_index   = sum_stats(Obs_Sim, param_save)\n",
    "# performing rejectio ABC. Note that if UMBER_SIMS is big enough, but rejection and regression ABC leads to teh same results.\n",
    "if abc_pref=='rejection':\n",
    "    result, HPDR=do_rejection(library)\n",
    "    print('see the results below')\n",
    "    print('Estimates from rejection is:', result)\n",
    "    print('Estimated HPDR from rejection is :', HPDR)\n",
    "# Next we have regression ABC, perform it if only you are not performing rejection ABC above. Gives better results for NUMBER_SIMS small. I have commented it.\n",
    "#  if abc_pref=='regression':\n",
    "#      library_reg=do_logit_transformation(library, param_bound)LJ=34, Ly=68, Linf=200 # AFH: still commented out because the code is a little messed up\n",
    "#      result_reg, HPDR_reg=do_kernel_ridge(stats, library_reg, param_bound)\n",
    "PARAMS1={}\n",
    "print(result[2]) # what are each of these? can we add a name column? \n",
    "PARAMS1 = {\"L_0\":result[0] , \"L_inf\": result[1],\"L_J\": 39.75,\"L_Y\": 67.5, \"Topt\": result[2], \"width\": result[3], \"kopt\": result[4],\"xi\":result[5], \"m_J\": result[6], \"m_Y\":result[7] , \"m_A\": result[8], \"K\": result[9]}\n",
    "\n",
    "N_J1, N_Y1, N_A1 = simulation_population(PARAMS1) #AF: it appears that N_J1 contains the simulations for juveniles--all of them, not just patch 1? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Latitude     State  Abundance\n",
      "0    2008        29  smalljuv   0.000000\n",
      "1    2008        29  largejuv   0.000000\n",
      "2    2008        29     adult  20.000000\n",
      "3    2009        29  smalljuv  20.106365\n",
      "4    2009        29  largejuv   0.000000\n",
      "..    ...       ...       ...        ...\n",
      "535  2016        46  largejuv   0.000000\n",
      "536  2016        46     adult   0.000000\n",
      "537  2017        46  smalljuv   0.000000\n",
      "538  2017        46  largejuv   0.000000\n",
      "539  2017        46     adult   0.000000\n",
      "\n",
      "[540 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# trying to write out results of model to plot in R \n",
    "#print(type(N_J1))\n",
    "#testdf = pd.DataFrame(N_J1)\n",
    "\n",
    "#print(nn)\n",
    "#print(testdf) # I think this has patch as columns and years as rows. would be nice to preserve the real year and patch IDs \n",
    "\n",
    "# Jude's code to write out to df \n",
    "\n",
    "print(PARAMS1)\n",
    "\n",
    "yr=[]\n",
    "lat=[]\n",
    "stage=[]\n",
    "abun=[]\n",
    "for p in range(no_patches):\n",
    "    for q in range(no_years):\n",
    "        abun.append(N_J1[:,p][q])\n",
    "        lat.append(latrange.min()+p) #lat.append(36+p)\n",
    "        yr.append(year_split+q) #yr.append(2013+q)\n",
    "        stage.append('smalljuv')\n",
    "        abun.append(N_Y1[:,p][q])\n",
    "        lat.append(latrange.min()+p) #lat.append(36+p)\n",
    "        yr.append(year_split+q) #yr.append(2013+q)\n",
    "        stage.append('largejuv')\n",
    "        abun.append(N_A1[:,p][q])\n",
    "        lat.append(latrange.min()+p) #lat.append(36+p)\n",
    "        yr.append(year_split+q) #yr.append(2013+q)\n",
    "        stage.append('adult')\n",
    "df=pd.DataFrame({'Year': yr, 'Latitude':lat, 'State': stage, 'Abundance': abun})\n",
    "print(df)\n",
    "\n",
    "df.to_csv('spiny_dogfish_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 45, index implies 33.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3080867c0ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_realdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_J1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_J\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'J_abun_rej'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#plot.do_scatter(N_J1[:,i], N_J[:,i],  'J_abun_scatter'+ str(p))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_realdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_Y1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'Y_abun_rej'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/mid_atlantic_process_models/scripts/jude_plot_code.py\u001b[0m in \u001b[0;36mdo_realdata\u001b[0;34m(NS, NO, filename)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_realdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mNO\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1980\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2013\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mNS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1980\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2013\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                         raise ValueError(\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0;34mf\"Length of passed values is {len(data)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m                             \u001b[0;34mf\"index implies {len(index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                         )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 45, index implies 33."
     ]
    }
   ],
   "source": [
    "#Importing a file call plot to plot the results.\n",
    "# print('i just imported a plot')\n",
    "for q in range(1,no_patches+1):\n",
    "    i=q-1\n",
    "    p=q\n",
    "    plot.do_realdata(N_J1[:,i], N_J[:,i],  'J_abun_rej'+ str(p))\n",
    "    #plot.do_scatter(N_J1[:,i], N_J[:,i],  'J_abun_scatter'+ str(p))\n",
    "    plot.do_realdata(N_Y1[:,i], N_Y[:,i],  'Y_abun_rej'+ str(p))\n",
    "    #plot.do_scatter(N_Y1[:,i], N_Y[:,i],  'Y_abun_scatter'+ str(p))\n",
    "    plot.do_realdata(N_A1[:,i], N_A[:,i],  'A_abun_rej'+ str(p))\n",
    "#plot.do_scatter(N_A1[:,i], N_A[:,i],  'A_abun_scatter'+ str(p))\n",
    "################################################################\n",
    "# plot the figures below if you willl like to plot the heatmap\n",
    "    NJ1=N_J1.transpose()\n",
    "    NJ=N_J.transpose()\n",
    "    NY1=N_Y1.transpose()\n",
    "    NY=N_Y.transpose()\n",
    "    NA1=N_A1.transpose()\n",
    "    NA=N_A.transpose()\n",
    "    print(NJ1.shape)\n",
    "    ax=sns.heatmap(NJ1, cmap=\"Greys\", xticklabels=True, yticklabels=True,  cbar_kws={'label': 'Abundance'})\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    ax.set_xticklabels(pd.Series(range(1980, 2012)))\n",
    "    ax.set_yticklabels(pd.Series(range(34, 46)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.figure.savefig(\"sim_J.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "#############################################################\n",
    "    ax = sns.heatmap(NJ, cmap=\"Greys\",  xticklabels=True, yticklabels=True, cbar_kws={'label': 'Abundance'})\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    ax.set_xticklabels(pd.Series(range(1980, 2012)))\n",
    "    ax.set_yticklabels(pd.Series(range(34, 46)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.figure.savefig(\"Obs_J.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "##########################################################\n",
    "    ax = sns.heatmap(NY1, cmap=\"Greys\", xticklabels=True, yticklabels=True,  cbar_kws={'label': 'Abundance'})\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    ax.set_xticklabels(pd.Series(range(1980, 2013)))\n",
    "    ax.set_yticklabels(pd.Series(range(34, 46)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.figure.savefig(\"Sim_Y.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "##########################################################\n",
    "    ax = sns.heatmap(NY, cmap=\"Greys\", xticklabels=True, yticklabels=True,  cbar_kws={'label': 'Abundance'})\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    ax.set_xticklabels(pd.Series(range(1980, 2013)))\n",
    "    ax.set_yticklabels(pd.Series(range(34, 46)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.figure.savefig(\"Obs_Y.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "############################################################\n",
    "    ax = sns.heatmap(NA1, cmap=\"Greys\", xticklabels=True, yticklabels=True, cbar_kws={'label': 'Abundance'})\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    ax.set_xticklabels(pd.Series(range(1980, 2013)))\n",
    "    ax.set_yticklabels(pd.Series(range(34, 46)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.figure.savefig(\"Sim_A.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "############################################################\n",
    "    ax = sns.heatmap(NA, cmap=\"Greys\",  xticklabels=True, yticklabels=True, cbar_kws={'label': 'Abundance'})\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    ax.set_xticklabels(pd.Series(range(1980, 2013)))\n",
    "    ax.set_yticklabels(pd.Series(range(34, 46)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.figure.savefig(\"Obs_A.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
