---
title: "Dynamic range model in Stan"
author: "Alexa Fredston and Malin Pinsky"
date: "begun November 2020"
output: html_document
---

## General notes

Useful sources for Bayesian population models and Bayesian implementation in R that we referenced while building this script: 

* https://github.com/DanOvando/learn-stan 
* https://arxiv.org/src/2002.02001v1/anc/Appendix_S1.pdf p. 72
* https://cchecastaldo.github.io/BayesianShortCourse/Syllabus.html
* https://mc-stan.org/docs/2_25/stan-users-guide/mark-recapture-models.html 
* https://mc-stan.org/docs/2_25/functions-reference/nbalt.html (and entire manual)

## Model notes

* Stan can't estimate discrete latent variables, so we've moved N from being discrete to continuous

## To-do (short term) 

* Revisit choices of initial values, especially when adding in dimensions over which variables are indexed, which will reduce the total number of individuals in each cell
* Add random Poisson noise around estimates of N every year (took this out to ensure Stan model was working correctly)
* Move away from uniform priors (done?)
* Figure out how to deal with true NAs in data, which are instances with no samples of a patch in a year (not true zeroes, although I've replaced them with zeroes temporarily)
* Add stage structure and transition rates 
* Add in dispersal between patches
* Replace r (and/or dispersal rates) with temperature-dependent functions
* Choose data models for all species (currently just modeling fluke) 

```{r packages}
library(rstan)
library(rstanarm)
library(tidybayes)
library(bayesplot)
```


```{r data, eval=TRUE}
#library(rjags)
library(tidyverse)
library(here)
#library(MCMCvis)

# dogfish <- read_csv(here("processed-data","dogfish_prepped_data.csv"))

# dogfishTest <- dogfish %>% 
#   filter(lengthclass=="adult") %>% 
#   group_by(year) %>% 
#   mutate(num_obs = sum(numlengthclass),
#          sd_obs = sd(numlengthclass)) %>% # this is standard deviation of different counts in a year, not of overall abundance over time
#   select(year, num_obs, sd_obs) %>% 
#   distinct()
# moving away from spiny dogfish because it is massively overdispersed and no single distribution will be able to produce values at low densities (1, 3, 10...) and at very high densities (5000, 8000, 10000) of dogfish; will eventually need a mixture model, and/or to totally disregard small values and assume everything under some threshold is basically equivalent

fluke <- read_csv(here("processed-data","fluke_prepped_data.csv"))

fluke_lat_time <- fluke %>% 
  mutate(lat_round = round(lat)) %>% 
  filter(lengthclass=="adult",
         year>=1972,
         lat_round >= 34 # because we're just using nefsc survey for now, which rarely goes below 34N
         ) %>% 
  group_by(year, lat_round) %>% 
  summarise(num_obs = sum(numlengthclass)) %>% 
  ungroup()

fluke_train <- fluke_lat_time %>% 
  filter(year <= 2008)

fluke_test <- fluke_lat_time %>% 
  filter(year > 2008)
```

Here's the stan script: 

```{stan, output.var="model1"}

data{
int<lower=1> len_t; // the number of time points
int<lower=0> len_i; // number of patches 

int<lower=0> y[len_i, len_t]; // defining y as an array of integers with patches as rows and years as columns

// data inputs
vector<lower=0>[len_i] z0; // vector of starting pop. values, one per patch 
real<lower=0> sd0; // scalar
} 

//transformed data{
//}

parameters{ 
real<lower=0> r; // intrinsic pop growth rate
real<lower=0, upper=100000> K; // carrying capacity
real<lower=0> sigma_process; 
real<lower=0> phi_obs; 

real<lower=0> N[len_i,len_t]; // array of population size--should be discrete (integer values), but Stan can't estimate latent discrete variables, so we're estimating it as continuous here 
vector<lower=0>[len_i] lambda0; // Ricker growth parameter at time step 1
vector<lower=1e3, upper=1e7>[len_i] gamma_shape0; // gamma parameter for process model at time step 1 - manually setting range
vector<lower=1, upper=1e3>[len_i] gamma_rate0; // gamma parameter for process model at time step 1 - manually setting range

} 

transformed parameters {
real<lower=0> lambda[len_i,len_t];
real<lower=0> gamma_shape[len_i,len_t]; 
real<lower=0> gamma_rate[len_i,len_t];

for(i in 1:len_i){
  lambda[i,1] = lambda0[i]; // assigning patches all the same initial values for now
  gamma_shape[i,1] = gamma_shape0[i];
  gamma_rate[i,1] = gamma_rate0[i];

}

for(t in 2:len_t){
  for(i in 1:len_i){
    lambda[i,t] = N[i,t-1] * exp(r - r * N[i,t-1] / K); 
    gamma_shape[i,t] = (lambda[i,t]^2) / (sigma_process^2);
    gamma_rate[i,t] = lambda[i,t] / (sigma_process^2);
}}
}

model{

// uniforms not strictly necessary if the bounds are appropriately declared in 
// the parameters block -- keeping for now as dists may change
K ~ uniform(100, 10000);
sigma_process ~ uniform(0, 500); //can we constrain this more?

r ~ normal(1, 1);
phi_obs ~ normal(0.75, 0.25); // from https://mc-stan.org/docs/2_20/functions-reference/nbalt.html  phi = mu^2 / (sigma^2-mu)

// define initial values of time-varying latent variables 
for(i in 1:len_i){
  N[i,1] ~ gamma((z0[i]^2/sd0^2),(z0[i]/sd0^2));
  lambda0[i] ~ gamma((z0[i]^2/sd0^2),(z0[i]/sd0^2));
  gamma_shape0[i] ~ uniform(1e3, 1e7);
  gamma_rate0[i] ~ uniform(1, 1000);
}

//define later values of N (other quantities are defined, not estimated, after the first value)
for(t in 2:len_t){
  for(i in 1:len_i){
N[i,t] ~ gamma(gamma_shape[i,t], gamma_rate[i,t]);  
}}

// observation model
for(t in 1:len_t) 
  for(i in 1:len_i)
    y[i,t] ~ neg_binomial_2(N[i,t], phi_obs); // this version of neg binom has a more familiar form 

}

```

And model implementation from R:

```{r model1, echo=FALSE, results='hide', message=FALSE, refresh=0}
warmups <- 1000

total_iterations <- 20000

max_treedepth <-  10

n_chains <-  4

n_cores <- 1

y_array <- reshape2::acast(fluke_train, lat_round~year, value.var="num_obs") # could also do this with pivot_wider
y_array <- replace_na(y_array, 0) # DANGER! this is writing over true NAs (years with zero samples in a lat band) with zeroes. I'm doing this here for coding simplicity but need to fix it later.
z0 <- fluke_train %>% filter(year == min(year)) %>% arrange(lat_round) %>% pull(num_obs)

# starting values from real data 
dataStan1 <- list(len_t=length(unique(fluke_train$year)),
                  len_i=length(unique(fluke_train$lat_round)),
                  y=y_array, # matrix of real pop. sizes; should have dimensions [len_i, len_t]
                  z0=z0, # vector of starting pop. sizes from lowest lat to highest; should have length of len_i
                  sd0=sd(z0) # keep this as a single value for now? also, should it be sd of year 1 or all years? 
)

## DANGER! replacing 0s with 1s here just so gamma will work, but we are writing over the real data!
dataStan1$z0 <- ifelse(dataStan1$z0>0, dataStan1$z0, 1)

# starting values for parameters, to initialize chains (all drawn from distributions... eventually need to set.seed) 
initStan1 <- list()
for(i in 1:n_chains) {
  phiinit <- rnorm(1, mean=0.75,
                   sd=0.25)
  sdpinit <- runif(1, runif(1, min=0, max=10),
                   max=runif(1, min=10, max=500)
                   )
  rinit <- rnorm(1, mean=0.75,
                 sd=0.25)
  Kinit <- runif(1, min=1000,
                 max=10000)
  
  initStan1[[i]] <- list(
    phi_obs = phiinit, 
    sigma_process=sdpinit, 
    r=rinit, 
    K=Kinit
  )
}

model1_fit <- # stan(file = here::here("R","model1.stan"),
  sampling(model1,
           data = dataStan1,
           chains = n_chains,
           warmup = warmups,
           iter = total_iterations,
           cores = n_cores,
           refresh = 250,
           init = initStan1,
           control = list(max_treedepth = max_treedepth,
                          adapt_delta = 0.95))
```

Evaluating the model:

```{r model1 eval}
summary(model1_fit)
plot(model1_fit)
check_divergences(model1_fit)
# rstanarm::launch_shinystan(model1_fit)

# convert to a df 
model1_summary <- summary(model1_fit)$summary %>% 
  as.data.frame() %>% 
  mutate(variable = rownames(.)) %>% 
  select(variable, everything()) %>% 
  as_tibble()

# pull out just N and plot 
model1_N <- model1_summary %>% 
  filter(str_detect(variable,'N\\[')) %>% 
  separate(variable, c("variable","temp"), sep = "\\[") %>% 
  separate(temp, c("patch","year_t"), sep=",") %>% 
  mutate(year_t = str_remove(year_t, '\\]'),
         year_t = as.numeric(year_t),
         patch = as.numeric(patch), 
         lat = patch + min(fluke_lat_time$lat_round) - 1,
         year = year_t + min(fluke_lat_time$year) - 1)
```

```{r model1 plot}

# plot abundance time-series by patch
model1_N %>% ggplot(aes(x=year, y=mean)) +
  geom_point() +
  geom_line() +
  facet_wrap(~lat)

```

